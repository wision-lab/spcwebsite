{% extends "base.html" %}

{% block content %}

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/stackoverflow-light.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js"></script>
<script>hljs.highlightAll();</script>

<h3>Frequently Asked Questions</h3>

<h4>What is a single photon camera?</h4>
<p>
    Single photon cameras are an emerging class of sensors that are capable of detecting and counting individual photons at ultra-high speeds, reaching up to 100 kHz. You can read more about their <a href="https://visionsim.readthedocs.io/en/latest/sections/sensors/spcs/passive_spc.html">image formation model here.</a> 
</p>



<h4>How to register?</h4>
<p>
    In order to submit to the benchmark you first need to register. Please note that in order to <a href="{% url 'download' %}">download</a> the dataset, no registration is needed. To register, first <a href="{% url 'core:signup' %}">create an account</a> and confirm your mail address by clicking on the link we will send to you.
</p>



<h4>What format is the dataset stored as?</h4>
<p>
    The training set is structured as pairs of ground truth images and their associated photoncubes, namely <span class="inline-code">&lt;SCENE-NAME&gt;/&lt;FRAME-IDX&gt;.png</span> and <span class="inline-code">&lt;SCENE-NAME&gt;/&lt;FRAME-IDX&gt;.npy</span>. The photoncubes are encoded as width-wise bitpacked numpy arrays, with unpacked dimensions of (1024, 800, 800, 3). To read these you can use numpy like so:
    <pre style="padding: 0;"><code class="language-python">import numpy as np 

# Load with memory mapping to avoid loading everything into RAM 
photoncube = np.load("datasets/train/attic/000000.npy", mmap_mode="r")
print(photoncube.shape)  # (1024, 800, 100, 3)

# Take first 10 binary frames 
bitplanes = np.unpackbits(photoncube[:10], axis=2)
print(bitplanes.shape)  # (10, 800, 800, 3)
</code></pre> 

    The test set is structured the exact same way, with the exception that ground truth reconstructions are not made public.   
</p>



<h4>How to submit my results to the benchmark?</h4>
<p>
    To submit your results to the benchmark, you need to zip them up into a single submission file. Importantly, the structure of this zip file should <u><i>exactly match</i></u> that of the test set. That is, the folder structure inside the zip file should be <span class="inline-code">&lt;SCENE-NAME&gt;/&lt;FRAME-IDX&gt;.png</span> without any other directories. All test samples, and nothing but the test samples are expected and will be accepted.  
</p>

<h5>A naive implementation</h5>
<p>
    The simplest way to reconstruct an image from single photon (binary) frames, is to simply sum them up. We provide a simple implementation of this baseline here as a reference, feel free to run this locally to inspect the generated submission file, but please do not upload <span class="inline-code">naivesum</span> results, as these have already been evaluated <a href="{% url 'eval:reconstruction' %}">here</a>.   
</p>
<pre style="padding: 0;"><code class="language-python">from pathlib import Path
from zipfile import ZipFile

import numpy as np
import imageio.v3 as iio
from rich.progress import track

from visionsim.emulate.spc import spc_avg_to_rgb
from visionsim.utils.color import linearrgb_to_srgb


def naivesum(
    testset: Path,
    tonemap: bool = False,
    invert_response: bool = False,
    batch_size: int = 1024,
):
    with ZipFile("submission.zip", "w") as zipf:
        for binary_path in track(list(testset.glob("**/*.npy"))):
            with zipf.open(
                str(binary_path.with_suffix(".png").relative_to(testset)), "w"
            ) as f:
                # Unpack and average last few binary frames
                pc = np.load(binary_path)
                pc = np.unpackbits(pc[-batch_size:], axis=2)
                im = pc.sum(axis=0) / batch_size

                # Optionally invert the single photon camera's response 
                # function and tonemap the image back to sRGB  
                im = spc_avg_to_rgb(im, factor=0.5) if invert_response else im
                im = linearrgb_to_srgb(im) if tonemap else im

                # Convert to uint8 and save into zipfile
                im = (im * 255).astype(np.uint8)
                iio.imwrite(f, im, extension=".png")</code></pre>

<p>
    <u>Note:</u> We show how to directly save results into a zip here, but you can of course create the archive manually after the fact as well. 
</p>


<h4>Can I benchmark my method without participating in the ongoing competition?</h4>
<p>
    Of course! You can always submit your results for evaluation and not participate in the competition. However, to participate in the competition you must not only submit your results for evaluation here, but also follow submit additional information about your method. Competition guidelines can <a href="https://cvspc.cs.pdx.edu/#competition">be found here.</a>
</p>


<h4>Further Questions?</h4>
<p>
    Please <a href="https://wisionlab.com/people/sacha-jungerman/">contact us here</a>.
</p>

{% endblock %}